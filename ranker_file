cache = {}#dictionary goes in here

index={}
def crawl_page(seed):
    tocrawl = [seed]
    crawled = []
    graph = {}
    skills=[] #keywords go here
    while tocrawl:
        job = tocrawl.pop()
        if job not in crawled:
            content = get_page(job)
            add_page_to_index(index, skills, job, content)
            return index


def skill_calculator(list):
	for a in list:
		crawl_page(a)
	return index

def get_page(url):
    if url in cache:
        return cache[url]
    else:
        return None

def add_page_to_index(index, skills, job, content):
	import re
	words=re.split('[; |, | |\*|\n]',content)
    	for word in words:
    		for a in skills:
    			if word == a:
        			if word in index:
            				index[word].append(job)
        			else:
            				index[word] = [job]

def compute_ranks(graph):
    d = 0.8 # damping factor
    numloops = 10

    ranks = {}
    npages = len(graph)
    for page in graph:
        ranks[page] = 1.0 / npages

    for i in range(0, numloops):
        newranks = {}
        for page in graph:
            newrank = (1 - d) / npages

            for node in graph:
                if page in graph[node]:
                    newrank=newrank+(d*ranks[node])/len(graph[node])
            newranks[page] = newrank
        ranks = newranks
    return ranks


a=skill_calculator(cache)
print ' '.join(sorted(a, key=lambda k: len(a[k]), reverse=True))












