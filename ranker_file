cache = {}#dictionary goes in here

index={}
def crawl_page(seed):#function that goes through the dictionary by keys and takes 
		     #Strings that exist in skills and adds them to index.
    tocrawl = [seed]
    crawled = []
    graph = {}
    skills=[] #keywords go here
    while tocrawl:
        job = tocrawl.pop()
        if job not in crawled:
            content = get_page(job)
            add_page_to_index(index, skills, job, content)
            return index


def skill_calculator(list): #function that crawls through each element in list
	for a in list:
		crawl_page(a)
	return index

def get_page(url):	#checks to make sure the key is in the dictionary of values to be ranked
    if url in cache:
        return cache[url]
    else:
        return None

def add_page_to_index(index, skills, job, content): #splits values of keys in cache and checks if values are in skills.
							# if they are, it adds the value to index.
	import re
	words=re.split('[; |, | |\*|\n]',content)
    	for word in words:
    		for a in skills:
    			if word == a:
        			if word in index:
            				index[word].append(job)
        			else:
            				index[word] = [job]

def compute_ranks(graph):	#function that is the algorithm to rank values in index.
				# same function as Google's original search algorithm.
    d = 0.8 # damping factor
    numloops = 10

    ranks = {}
    npages = len(graph)
    for page in graph:
        ranks[page] = 1.0 / npages

    for i in range(0, numloops):
        newranks = {}
        for page in graph:
            newrank = (1 - d) / npages

            for node in graph:
                if page in graph[node]:
                    newrank=newrank+(d*ranks[node])/len(graph[node])
            newranks[page] = newrank
        ranks = newranks
    return ranks


a=skill_calculator(cache) #creates list of ranked values of dictionary as a.
print ' '.join(sorted(a, key=lambda k: len(a[k]), reverse=True)) #organizes list












